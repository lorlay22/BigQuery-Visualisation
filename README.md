# AI-Powered BigQuery Schema Visualizer

This project is a Python tool that connects to a Google Cloud project, analyzes the schemas of all BigQuery datasets, and generates an interactive data map as a graph. It uses a combination of heuristic analysis and artificial intelligence (semantic embeddings) to infer and visualize the relationships between tables.

The goal is to provide a clear and explorable overview of a data estate, thereby facilitating data discovery and lineage comprehension.

## ‚ú® Key Features

* **Automatic BigQuery Connection**: Fetches the schemas of all datasets within a specified GCP project.
* **Heuristic Analysis**: Uses regular expressions and business rules to identify columns that act as keys (primary/foreign keys).
* **Logical Graph Construction**: Models the relationships between datasets, tables, and columns using the `NetworkX` library.
* **Interactive HTML Visualization**: Generates a single, self-contained HTML file with a dynamic and explorable visualization powered by `Pyvis`.
* **"Drill-Down" Interface**:
    * Start with a high-level view of all datasets.
    * Click on a dataset to see the tables it contains.
    * Click on a table to display all its columns.
    * Click on a key column to see where else it is used.
* **Semantic Search (AI)**: A search bar allows finding columns by their meaning, not just their exact name, thanks to text embeddings generated by `Sentence-Transformers`. For example, searching for "customer identifier" can find columns named `customer_id`, `cust_ref`, or `user_num`.

## üõ†Ô∏è Tech Stack

* **Python 3**
* **Google Cloud SDK** (for the BigQuery API)
* **NetworkX**: For creating and manipulating the graph structure.
* **Pyvis**: For converting the NetworkX graph into an interactive HTML/JS visualization.
* **Sentence-Transformers**: For creating vector embeddings of column names to enable semantic search.
* **Numpy & Scikit-learn**: For calculating cosine similarity between vectors.

## üöÄ How to Use

### Prerequisites

* A Google Cloud account with a BigQuery project containing data.
* Python 3.7+ installed.
* Authenticated `gcloud` on your local machine.

### Installation

1.  **Clone this repository:**
    ```bash
    git clone [https://github.com/your-username/your-repo.git](https://github.com/your-username/your-repo.git)
    cd your-repo
    ```

2.  **Install dependencies:**
    *(It is recommended to use a virtual environment)*
    ```bash
    pip install google-cloud-bigquery networkx pyvis sentence-transformers scikit-learn numpy
    ```
3.  **Authenticate with Google Cloud (if not already done):**
    ```bash
    gcloud auth application-default login
    ```

### Configuration

Open the main script and modify the `Config` class:

* **`PROJECT_ID`**: Replace `"your-gcp-project-id"` with your own Google Cloud project ID.
* **`DATASETS_TO_PROCESS_FILTER`** (Optional): If you only want to analyze a few specific datasets, list them here (e.g., `["sales", "marketing"]`).

### Launching the Script

Simply run the script from your terminal:

```bash
python your_script_name.py
```

The script will connect to BigQuery, analyze the schemas, and generate a `schema_graph_... .html` file in the same directory. Open this file in your browser to explore the map!
